{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Tracer\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.losses\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "\n",
    "from scipy import io\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "import socket\n",
    "import socketserver\n",
    "import time\n",
    "import threading\n",
    "from IPython.display import clear_output\n",
    "\n",
    "np.set_printoptions(precision=10, suppress=True)\n",
    "def my_mape(y_true, y_pred):\n",
    "    return K.sum((K.abs(y_pred - y_true))/(K.abs(y_true)+0.001))\n",
    "keras.losses.my_mape = my_mape\n",
    "\n",
    "serverSocket =socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
    "serverSocket.bind (('127.0.0.1',50000))\n",
    "serverSocket.listen(1)\n",
    "\n",
    "Q_max = np.genfromtxt('./MATLAB/data/Generate/0601/temp_0601_0.csv', delimiter=',')[:,20:35].max(axis = 0)\n",
    "Q_min = np.genfromtxt('./MATLAB/data/Generate/0601/temp_0601_0.csv', delimiter=',')[:,20:35].min(axis = 0)\n",
    "def Q_normalize(Q_num):\n",
    "    return (Q_num - Q_min)/(Q_max - Q_min)\n",
    "\n",
    "def Q_denormalize(X_pred_nor):\n",
    "    res = X_pred_nor.copy()\n",
    "    Freq = res[:,2:20]\n",
    "    res[:,2:20] = np.power(10, Freq)\n",
    "    Q_num = res[:,20:]\n",
    "    Q_num = Q_num*(Q_max - Q_min)+Q_min\n",
    "    res[:,20:] = Q_num\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./MATLAB/data/0609/X/ 300 files\n",
      "./MATLAB/data/0609/Z/ 300 files\n",
      "finish\n",
      "(300, 1) (300, 15) (300, 16) (300,)\n"
     ]
    }
   ],
   "source": [
    "X_in_ = []\n",
    "X_out_ = []\n",
    "Y_in_ = []\n",
    "Y_out_ = []\n",
    "indices_ = []\n",
    "\n",
    "# Load datas\n",
    "directory_name = './MATLAB/data/0609/'\n",
    "# data_amount = 7500\n",
    "\n",
    "X_DesignedFs = []\n",
    "X_poles = []\n",
    "X_Qnums = []\n",
    "X_LQ = []\n",
    "# X_rks = []\n",
    "# X_yks = []\n",
    "# X_uks = []\n",
    "X_eks = []\n",
    "Z_DesignedFs = []\n",
    "Z_poles = []\n",
    "Z_Qnums = []\n",
    "Z_LQ = []\n",
    "# Z_rks = []\n",
    "# Z_yks = []\n",
    "# Z_uks = []\n",
    "Z_eks = []\n",
    "for plant_dir in ['X/', 'Z/']:\n",
    "    files_name = os.listdir(directory_name+plant_dir)\n",
    "    print(directory_name+plant_dir, len(files_name), 'files')\n",
    "    for file in files_name:\n",
    "#     for file in files_name[:data_amount]:\n",
    "        load_data = io.loadmat(directory_name + plant_dir + file)\n",
    "        plant = file[0]\n",
    "        DesignedF = load_data[plant+'_DesignedF']\n",
    "        pole = load_data[plant+'_pole'].reshape(-1)[0]\n",
    "        Qnum = load_data[plant+'_Qnum'].reshape(-1)\n",
    "        LQ = Qnum.shape[0]\n",
    "#         rk = (load_data[plant+'_rk'].reshape(-1))[7500:22500]\n",
    "#         yk = (load_data[plant+'_yk'].reshape(-1))[7500:22500]\n",
    "#         uk = (load_data[plant+'_uk'].reshape(-1))[7500:22500]\n",
    "        ek = (load_data[plant+'_ek'].reshape(-1))[7500:22500]\n",
    "    #     print(file, ek.max())\n",
    "        if ek.max() < 25:\n",
    "            if plant == 'X':\n",
    "                X_DesignedFs.append(DesignedF)\n",
    "                X_poles.append(pole)\n",
    "                X_Qnums.append(Qnum)\n",
    "                X_LQ.append(LQ)\n",
    "#                 X_rks.append(rk)\n",
    "#                 X_yks.append(yk)\n",
    "#                 X_uks.append(uk)\n",
    "                X_eks.append(ek)\n",
    "            elif plant == 'Z':\n",
    "                Z_DesignedFs.append(DesignedF)\n",
    "                Z_poles.append(pole)\n",
    "                Z_Qnums.append(Qnum)\n",
    "                Z_LQ.append(LQ)\n",
    "#                 Z_rks.append(rk)\n",
    "#                 Z_yks.append(yk)\n",
    "#                 Z_uks.append(uk)\n",
    "                Z_eks.append(ek)\n",
    "X_poles = np.array(X_poles)\n",
    "X_LQ = np.array(X_LQ)\n",
    "# X_rks = np.array(X_rks)\n",
    "# X_yks = np.array(X_yks)\n",
    "# X_uks = np.array(X_uks)\n",
    "X_eks = np.array(X_eks)\n",
    "X_Qnums = np.array(X_Qnums)\n",
    "X_DesignedFs = np.array(X_DesignedFs)[:,:,1]\n",
    "Z_poles = np.array(Z_poles)\n",
    "Z_LQ = np.array(Z_LQ)\n",
    "# Z_rks = np.array(Z_rks)\n",
    "# Z_yks = np.array(Z_yks)\n",
    "# Z_uks = np.array(Z_uks)\n",
    "Z_eks = np.array(Z_eks)\n",
    "Z_Qnums = np.array(Z_Qnums)\n",
    "Z_DesignedFs = np.array(Z_DesignedFs)[:,:,1]\n",
    "\n",
    "Q_max = X_Qnums.max(axis = 0)\n",
    "Q_min = X_Qnums.min(axis = 0)\n",
    "print('finish')\n",
    "# X_in_.append(X_poles.reshape(-1, 1))\n",
    "# X_out_.append(Q_normalize(X_Qnums))\n",
    "Y_in_.append(np.append(X_in_[-1], X_out_[-1], axis = 1))\n",
    "Y_out_.append(X_eks.max(axis = 1))\n",
    "indices_.append(np.arange(X_in_[-1].shape[0]))\n",
    "np.random.shuffle(indices_[-1])\n",
    "print(X_in_[-1].shape, X_out_[-1].shape, Y_in_[-1].shape, Y_out_[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_in_ = []\n",
    "Y_out_ = []\n",
    "indices_ = []\n",
    "data_idx = [0, 1, 2, 5, 6, 7, 8, 24]\n",
    "total = 0\n",
    "for idx in data_idx:\n",
    "    p_LQ = np.genfromtxt('./MATLAB/data/Generate/0601/temp_0601_{}.csv'.format(idx), delimiter=',')[:,:2]\n",
    "    Freq = np.log10(np.genfromtxt('./MATLAB/data/Generate/0601/temp_0601_{}.csv'.format(idx), delimiter=',')[:,2:20])\n",
    "    Q = Q_normalize(np.genfromtxt('./MATLAB/data/Generate/0601/temp_0601_{}.csv'.format(idx), delimiter=',')[:,20:35])\n",
    "    Y_in_.append(np.hstack((p_LQ, Freq, Q)))\n",
    "    Y_out_.append(np.genfromtxt('./MATLAB/data/Generate/0601/temp_error_0601_{}.csv'.format(idx), delimiter=',')[:,0]*1000)\n",
    "    print(Y_in_[-1].shape, Y_out_[-1].shape)\n",
    "    indices_.append(np.arange(Y_in_[-1].shape[0]) + total)\n",
    "    total += Y_in_[-1].shape[0]\n",
    "    np.random.shuffle(indices_[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 16) (300, 0) (300, 16) (300,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (300,15) into shape (300,0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-33df305d98e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhost_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m211\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ_denormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m7324\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Original Q num'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-4f038bc3dfb9>\u001b[0m in \u001b[0;36mQ_denormalize\u001b[1;34m(X_pred_nor)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mQ_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mQ_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQ_num\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ_max\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mQ_min\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mQ_min\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQ_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (300,15) into shape (300,0)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_in = Y_in_[0][:,:20]\n",
    "X_out = Y_in_[0][:,20:35]\n",
    "Y_in = Y_in_[0]\n",
    "Y_out = Y_out_[0]\n",
    "for i in range(1,len(Y_out_)):\n",
    "    Y_in = np.append(Y_in, Y_in_[i], axis = 0)\n",
    "    Y_out = np.append(Y_out, Y_out_[i], axis = 0)\n",
    "Y_in = np.delete(Y_in, np.where(Y_out != Y_out), axis = 0)\n",
    "Y_out = np.delete(Y_out, np.where(Y_out != Y_out), axis = 0)\n",
    "print(X_in.shape, X_out.shape, Y_in.shape, Y_out.shape)\n",
    "indices = np.arange(Y_in.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 16))\n",
    "ax1 = host_subplot(211, axes_class=AA.Axes)\n",
    "for i in range(15):\n",
    "    ax1.plot(Q_denormalize(Y_in)[:,i+1], alpha = 0.5)\n",
    "    ax1.set_title('Original Q num')\n",
    "    \n",
    "\n",
    "ax1 = host_subplot(212, axes_class=AA.Axes)\n",
    "ax1.plot(Y_out[:7324], alpha = 0.5)\n",
    "ax1.set_title('Original Err')\n",
    "# ax1.set_ylim(0,10)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 16))\n",
    "ax1 = host_subplot(211, axes_class=AA.Axes)\n",
    "for i in range(15):\n",
    "    ax1.plot(Q_denormalize(Y_in)[7324:,i+20], alpha = 0.5)\n",
    "    ax1.set_title('Original Q num')\n",
    "\n",
    "ax1 = host_subplot(212, axes_class=AA.Axes)\n",
    "ax1.plot(Y_out[7324:], alpha = 0.5)\n",
    "ax1.set_title('Original Err')\n",
    "# ax1.set_ylim(0,50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __discriminator():\n",
    "    \"\"\" Declare discriminator \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=32, input_dim=Y_in.shape[1], kernel_initializer='normal'))\n",
    "#     model.add(Dropout(0.1))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dense(units=64, kernel_initializer='normal', activation='sigmoid'))\n",
    "#     model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(units=16, activation='sigmoid'))\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=1))\n",
    "    model.name = \"D\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __generator():\n",
    "    \"\"\" Declare generator \"\"\"\n",
    "    G_in = Input(shape = (X_in.shape[1],))\n",
    "    L1 = Dense(units=32, kernel_initializer='normal')(G_in)\n",
    "#     L1 = Dropout(0.1)(L1)\n",
    "    L1 = Dense(units = 64)(L1)\n",
    "#     L1 = Dropout(0.1)(L1)\n",
    "#     L1 = BatchNormalization()(L1)\n",
    "    L1 = Dense(units = 64, activation='sigmoid')(L1)\n",
    "#     L1 = Dropout(0.1)(L1)\n",
    "#     L1 = BatchNormalization()(L1)\n",
    "    L1 = Dense(units = 32)(L1)\n",
    "    G_out = Dense(units = X_out.shape[1])(L1)\n",
    "    G_out = Concatenate(axis = -1)([G_in, G_out])\n",
    "    model = Model(inputs = G_in, outputs = G_out)\n",
    "    model.name = \"G\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __stacked_generator_discriminator(self_G, self_D):\n",
    "    self_D.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(self_G)\n",
    "    model.add(self_D)\n",
    "    model.name = \"GD\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_D = __discriminator()\n",
    "self_D.compile(loss='mae', optimizer=Adam(lr=0.0001, beta_1=0.5, decay=8e-8))\n",
    "self_D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_G = __generator()\n",
    "self_G.compile(loss=my_mape, optimizer=Adam(lr=0.0001, beta_1=0.5, decay=8e-8))\n",
    "self_G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "self_stacked_GD = __stacked_generator_discriminator(self_G, self_D)\n",
    "self_stacked_GD.compile(loss='mae', optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8))\n",
    "self_stacked_GD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "self_D.trainable = True\n",
    "self_D.compile(loss = 'mae', optimizer = Nadam(lr=0.002))\n",
    "train_history_D = self_D.fit(x=Y_in, y=Y_out, \n",
    "                             validation_split=0, epochs=100000, batch_size=1024, verbose=1, \n",
    "                             callbacks = [tensorboard_callback, \n",
    "                                          EarlyStopping(monitor = 'loss', patience = 100, verbose = 1, mode = 'auto'), \n",
    "                                          EarlyStoppingByLossVal(monitor='val_loss', value=0.3, verbose=1),])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_G.compile(loss='mape', optimizer=Nadam(lr=0.002))\n",
    "train_history_G = self_G.fit(x=X_in, y=Y_in[:X_in.shape[0]],\n",
    "                               validation_split=0, epochs=10000, batch_size=1024, verbose=1, \n",
    "                               callbacks = [tensorboard_callback, EarlyStopping(monitor = 'loss', patience = 500, verbose = 1, mode = 'auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mislabled = np.zeros((Y_in_[0].shape[0], 1))\n",
    "self_D.trainable = False\n",
    "self_stacked_GD.compile(loss='mse', optimizer=Nadam(lr=0.002))\n",
    "train_history_GD = self_stacked_GD.fit(x=X_in[indices_[0]], y=Y_out[indices_[0]], \n",
    "# train_history_GD = self_stacked_GD.fit(x=X_in[:3750], y=mislabled,\n",
    "                                       validation_split=0.2, epochs=1000000, batch_size=1024, verbose=1, \n",
    "                                       callbacks = [tensorboard_callback, EarlyStopping(monitor = 'loss', patience = 500, verbose = 1, mode = 'auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "self_G = load_model('./models/Simulator_DesignF2Qnum_0601_4.h5') \n",
    "self_G.name = \"G\"\n",
    "self_G.compile(loss=my_mape, optimizer=Adam(lr=0.0000001, beta_1=0.5, decay=8e-8))\n",
    "self_G.summary()\n",
    "self_D = load_model('./models/Simulator_Qnum2Errmax_0601_4.h5')\n",
    "self_D.name = \"D\"\n",
    "self_D.compile(loss='mape', optimizer=Adam(lr=0.000001, beta_1=0.5, decay=8e-8))\n",
    "self_D.summary()\n",
    "\n",
    "self_stacked_GD = __stacked_generator_discriminator(self_G, self_D)\n",
    "self_stacked_GD.compile(loss='mae', optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8))\n",
    "self_stacked_GD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_G.save('./models/Simulator_DesignF2Qnum_0608_2.h5')\n",
    "self_D.save('./models/Simulator_Qnum2Errmax_0608_2.h5')\n",
    "self_stacked_GD.save('./models/Stacked_GAN_0608_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history_D = []\n",
    "train_history_GD = []\n",
    "idx = -1\n",
    "for idx in range(50):\n",
    "\n",
    "    X_pred = self_G.predict(X_in)\n",
    "    \n",
    "    with open('./MATLAB/data/Generate/temp.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(Q_denormalize(X_pred))\n",
    "    print(\"start matlab\")\n",
    "    os.system(r\"matlab -r \\\"run('C:\\Users\\dalek669528\\Desktop\\CNC_proj\\MATLAB\\Simulation_FixedQ_Ccode\\X_main_fixedQ_Ccode_func.m')\\\"\")\n",
    "    print(\"open socket\")\n",
    "    connectionSocket, addr = serverSocket.accept()\n",
    "    with open('./MATLAB/data/Generate/check_{}.csv'.format(idx), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(Q_denormalize(X_pred))\n",
    "    self_G.save('./models/checkpoint/G_{}.h5'.format(idx))\n",
    "    self_D.save('./models/checkpoint/D_{}.h5'.format(idx))\n",
    "    self_stacked_GD.save('./models/checkpoint/StackGD_{}.h5'.format(idx))\n",
    "    self_D.trainable = True\n",
    "    self_D.compile(loss='mae', optimizer=Adam(lr=0.00002, beta_1=0.5, decay=8e-8))\n",
    "    train_history_D.append(self_D.fit(x=Y_in[indices], y=Y_out[indices], \n",
    "                                      validation_split=0.3, epochs=1000, batch_size=256, verbose=1, \n",
    "                                      callbacks = [EarlyStopping(monitor = 'val_loss', patience = 200+idx*100, verbose = 1, mode = 'auto')]))\n",
    "\n",
    "    # mislabled = np.zeros((X_in_[0].shape[0], 1))\n",
    "    self_D.trainable = False\n",
    "    self_stacked_GD.compile(loss='mape', optimizer=Adam(lr=0.000001, beta_1=0.5, decay=8e-8))\n",
    "    train_history_GD.append(self_stacked_GD.fit(x=X_in[indices_[0]], y=Y_out[indices_[0]], \n",
    "                                                validation_split=0.3, epochs=100000, batch_size=256, verbose=1, \n",
    "                                                callbacks = [EarlyStopping(monitor = 'val_loss', patience = 500+idx*200, mode = 'auto')]))\n",
    "\n",
    "#     connectionSocket, addr = serverSocket.accept()\n",
    "    sentence = connectionSocket.recv(1024)\n",
    "    print(sentence.decode())\n",
    "    connectionSocket.close() \n",
    "    with open('./MATLAB/data/Generate/0601/temp_0601_{}.csv'.format(len(Y_out_)), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(np.genfromtxt('./MATLAB/data/Generate/temp.csv', delimiter=','))\n",
    "    with open('./MATLAB/data/Generate/0601/temp_error_0601_{}.csv'.format(len(Y_out_)), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(np.genfromtxt('./MATLAB/data/Generate/temp_error.csv', delimiter=','))    \n",
    "    p_LQ = np.genfromtxt('./MATLAB/data/Generate/temp.csv', delimiter=',')[:,:2]\n",
    "    Freq = np.log10(np.genfromtxt('./MATLAB/data/Generate/temp.csv', delimiter=',')[:,2:20])\n",
    "    Q = Q_normalize(np.genfromtxt('./MATLAB/data/Generate/temp.csv', delimiter=',')[:,20:35])\n",
    "    Y_in_resimulate = np.hstack((p_LQ, Freq, Q))\n",
    "    Y_out_resimulate = np.genfromtxt('./MATLAB/data/Generate/temp_error.csv', delimiter=',')[:,0]*1000\n",
    "    Y_in_.append(Y_in_resimulate)\n",
    "    Y_out_.append(Y_out_resimulate)\n",
    "    Y_in = np.append(Y_in, Y_in_resimulate, axis=0)\n",
    "    Y_out = np.append(Y_out, Y_out_resimulate)\n",
    "    Y_in = np.delete(Y_in, np.where(Y_out != Y_out), axis = 0)\n",
    "    Y_out = np.delete(Y_out, np.where(Y_out != Y_out), axis = 0)\n",
    "    print(Y_in_[-1].shape, Y_out_[-1].shape, len(Y_in))\n",
    "    indices = np.arange(Y_in.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./MATLAB/data/Generate/0601/temp_0601_{}.csv'.format(24), 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(np.genfromtxt('./MATLAB/data/Generate/temp.csv', delimiter=','))\n",
    "with open('./MATLAB/data/Generate/0601/temp_error_0601_{}.csv'.format(24), 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(np.genfromtxt('./MATLAB/data/Generate/temp_error.csv', delimiter=','))    \n",
    "p_LQ = np.genfromtxt('./MATLAB/data/Generate/temp.csv', delimiter=',')[:,:2]\n",
    "Freq = np.log10(np.genfromtxt('./MATLAB/data/Generate/temp.csv', delimiter=',')[:,2:20])\n",
    "Q = Q_normalize(np.genfromtxt('./MATLAB/data/Generate/temp.csv', delimiter=',')[:,20:35])\n",
    "Y_in_resimulate = np.hstack((p_LQ, Freq, Q))\n",
    "Y_out_resimulate = np.genfromtxt('./MATLAB/data/Generate/temp_error.csv', delimiter=',')[:,0]*1000\n",
    "Y_in_.append(Y_in_resimulate)\n",
    "Y_out_.append(Y_out_resimulate)\n",
    "Y_in = np.append(Y_in, Y_in_resimulate, axis=0)\n",
    "Y_out = np.append(Y_out, Y_out_resimulate)\n",
    "Y_in = np.delete(Y_in, np.where(Y_out != Y_out), axis = 0)\n",
    "Y_out = np.delete(Y_out, np.where(Y_out != Y_out), axis = 0)\n",
    "print(Y_in_[-1].shape, Y_out_[-1].shape, len(Y_in))\n",
    "indices = np.arange(Y_in.shape[0])\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_in_.append(Y_in_resimulate)\n",
    "Y_out_.append(Y_out_resimulate)\n",
    "Y_in = np.append(Y_in, Y_in_resimulate, axis=0)\n",
    "Y_out = np.append(Y_out, Y_out_resimulate)\n",
    "print(Y_in_[-1].shape, Y_out_[-1].shape, len(Y_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./MATLAB/data/Generate/temp_0430_{}.csv'.format(len(Y_out_)), 'w', newline='') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     writer.writerows(np.genfromtxt('./MATLAB/data/Generate/temp.csv', delimiter=','))\n",
    "# with open('./MATLAB/data/Generate/temp_error_0430_{}.csv'.format(len(Y_out_)), 'w', newline='') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     writer.writerows(np.genfromtxt('./MATLAB/data/Generate/temp_error.csv', delimiter=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_pred = self_G.predict(X_in)\n",
    "Y_pred = self_stacked_GD.predict(X_in)\n",
    "Y_pred_D = self_D.predict(Y_in_[-2])\n",
    "fig = plt.figure(figsize=(15, 16))\n",
    "ax1 = host_subplot(211, axes_class=AA.Axes)\n",
    "for i in range(15):\n",
    "    ax1.plot(Q_denormalize(Y_in_[-2])[:,i+20], alpha = 0.5)\n",
    "    ax1.set_title('Original Q num')\n",
    "ax1 = host_subplot(212, axes_class=AA.Axes)\n",
    "for i in range(15):\n",
    "    ax1.plot(Q_denormalize(X_pred)[:,i+20], alpha = 0.5)\n",
    "    ax1.set_title('Original Q num')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "ax1 = host_subplot(311, axes_class=AA.Axes)\n",
    "ax1.plot(Y_out_[-2], alpha = 0.5)\n",
    "ax1.set_title('Original Err')\n",
    "ax1 = host_subplot(312, axes_class=AA.Axes)\n",
    "ax1.plot(Y_pred, alpha = 0.5)\n",
    "ax1.set_title('Original Err')\n",
    "ax1 = host_subplot(313, axes_class=AA.Axes)\n",
    "ax1.plot(Y_pred_D, alpha = 0.5)\n",
    "ax1.set_title('Original Err')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 16))\n",
    "ax1 = host_subplot(211, axes_class=AA.Axes)\n",
    "for i in range(15):\n",
    "    ax1.plot(Q_denormalize(Y_in_[-1])[:,i+20], alpha = 0.5)\n",
    "    ax1.set_title('Original Q num')\n",
    "\n",
    "ax1 = host_subplot(212, axes_class=AA.Axes)\n",
    "ax1.plot(Y_out_[-1], alpha = 0.5)\n",
    "ax1.set_title('Original Err')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_denormalize(X_pred)[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_pred = self_G.predict(X_in)\n",
    "Y_pred = self_stacked_GD.predict(X_in)\n",
    "Y_pred_D = self_D.predict(Y_in)\n",
    "fig = plt.figure(figsize=(15, 16))\n",
    "ax1 = host_subplot(211, axes_class=AA.Axes)\n",
    "for i in range(15):\n",
    "    ax1.plot(Q_denormalize(Y_in_[0])[:,i+20], alpha = 0.5)\n",
    "    ax1.set_title('Original Q num')\n",
    "# plt.show()\n",
    "# fig = plt.figure(figsize=(15, 8))\n",
    "ax1 = host_subplot(212, axes_class=AA.Axes)\n",
    "for i in range(15):\n",
    "    ax1.plot(Q_denormalize(X_pred)[:,i+20], alpha = 0.8)\n",
    "    ax1.set_title('Predict Q num')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "ax1 = host_subplot(111, axes_class=AA.Axes)\n",
    "ax1.plot(Y_out_[0][indices_[0]], alpha = 1, label = \"Original error\")\n",
    "ax1.plot(Y_pred, alpha = 0.5, label = \"Predict error\")\n",
    "ax1.set_title('max error')\n",
    "ax1.legend()\n",
    "# ax1.set_ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "ax1 = host_subplot(111, axes_class=AA.Axes)\n",
    "ax1.plot(Y_out, alpha = 1, label = \"Original error\")\n",
    "ax1.plot(Y_pred_D, alpha = 0.3, label = \"Predict error\")\n",
    "ax1.set_title('max error')\n",
    "ax1.legend()\n",
    "# ax1.set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_D = self_D.predict(Y_in)\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "ax1 = host_subplot(111, axes_class=AA.Axes)\n",
    "ax1.plot(Y_out[:], alpha = 1, label = \"Original error\")\n",
    "ax1.plot(Y_pred_D[:], alpha = 0.3, label = \"Predict error\")\n",
    "ax1.set_title('max error')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_test = self_D.predict(Y_in)\n",
    "fig = plt.figure(figsize=(15, 16))\n",
    "ax1 = host_subplot(211, axes_class=AA.Axes)\n",
    "ax1.plot(Y_out_, alpha = 0.9)\n",
    "# ax1.plot(Y_test, alpha = 0.5)\n",
    "# ax1 = host_subplot(212, axes_class=AA.Axes)\n",
    "# ax1.plot(Y_out_3[:200], alpha = 0.9)\n",
    "# ax1.plot(Y_test[:200], alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(Y_out_)):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax1 = host_subplot(211, axes_class=AA.Axes)\n",
    "    for i in range(15):\n",
    "        ax1.plot(Q_denormalize(Y_in_[idx])[:,i+20], alpha = 0.5)\n",
    "    ax1.set_title(idx)\n",
    "#     ax1.set_xticklabels(['','3', '3.5', '4', '4.5', '5', '5.5', '6', '6.5'], fontsize = 30)\n",
    "#     plt.show()\n",
    "\n",
    "#     fig = plt.figure(figsize=(7, 5))\n",
    "    ax1 = host_subplot(212, axes_class=AA.Axes)\n",
    "    ax1.plot(Y_out_[idx], alpha = 0.5)\n",
    "    # ax1.set_title('Original Err')\n",
    "#     ax1.set_xticklabels(['','3', '3.5', '4', '4.5', '5', '5.5', '6', '6.5'], fontsize = 30)\n",
    "    ax1.set_ylim(0,25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ = np.genfromtxt('./MATLAB/data/Generate/0601/temp_0601_2.csv', delimiter=',')\n",
    "out_ = np.genfromtxt('./MATLAB/data/Generate/0601/temp_error_0601_2.csv', delimiter=',')\n",
    "print(in_.shape, out_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./MATLAB/data/Generate//0601/temp_0601_2.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(in_)\n",
    "with open('./MATLAB/data/Generate/0601/temp_error_0601_2.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(out_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
